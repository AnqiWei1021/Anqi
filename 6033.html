<h2>Introduction</h2>

<p>
Through this semester’s study of digital technology and large models, I slowly realized that 
digital technology is more complex than our imagination. Its convenience always hides behind 
a huge foundation of material, labour, and environmental consumption. The issues of energy 
usage, resource exploitation, and bias in knowledge production are especially unavoidable.
</p>

<p>
Therefore, this article conducts reflections from three interconnected levels:
</p>

<ul>
    <li>Understanding how AI relies on resource extraction, data collection, and global supply chains.</li>
    <li>Discussing how digital technology brings energy consumption and environmental burdens.</li>
    <li>Analyzing how large models create biases, misinformation, and affect society and knowledge production.</li>
</ul>

<p>
I hope this article reminds us that digital humanities should not ignore ethical, environmental, 
and systemic influences behind technological operations.
</p>


<hr>

<h2>1. The operation of AI relies on resources, data, and global supply chains</h2>

<p>
Before reading “Anatomy of an AI System” (Crawford & Joler, 2018), I did not realize that behind 
the seemingly lightweight operations of AI systems, there is an enormous investment of material 
foundations, labour, and energy. This article discusses three hidden costs: resource exploitation, 
data extraction, and a complex global supply chain.
</p>

<h3>1.1 Exploitation of resources</h3>

<p>
Intelligent devices rely heavily on rare metal mining, such as lithium, cobalt, and other minerals.
While these materials support technological development, they often come from regions experiencing 
environmental destruction, ecological imbalance, and labour exploitation. These hidden costs
contrast sharply with the clean, futuristic interface of smart devices, concealing the environmental 
damage involved.
</p>

<!-- IMAGE placeholder: Exploitation of resources -->
<!-- <img src="images/your-filename-1.png" alt="Exploitation of resources"> -->


<h3>1.2 Data and privacy extraction</h3>

<p>
When an AI device operates, it continuously collects user data, often without explicit consent. 
This leads to concerns over data ownership, privacy boundaries, and the authority of digital 
platforms. Once personal data becomes commodified, technology gains the power to reshape how 
information flows and how individuals are represented.
</p>

<!-- IMAGE placeholder: Cybersecurity -->
<!-- <img src="images/your-filename-2.png" alt="Cybersecurity image"> -->


<h3>1.3 Global supply chain</h3>

<p>
The production of intelligent technologies involves a global supply chain composed of material 
production, labour assembly, and long-distance transportation. Although the AI interface appears 
intangible, the supply chain behind it is highly material, energy-consuming, and environmentally 
costly. This reveals that AI is not purely a digital object—it is deeply embedded in global 
economic structures.
</p>

<!-- IMAGE placeholder: Global supply chain -->
<!-- <img src="images/your-filename-3.png" alt="Global supply chain"> -->


<p>
This section made me realize that the operation of AI relies not only on computation but also on 
material foundations, labour distribution, and resource consumption. Every technological 
advancement has a real-world environmental and human cost.
</p>

<hr>

<h2>2. Digital technology brings energy consumption and environmental burdens</h2>

<p>
Large models such as GPT and LLMs require enormous energy for training. Data centers must run 
continuously at low temperatures, consuming electricity and water resources at extreme levels. 
In the digital humanities context, this raises the question: How can we responsibly use these 
technologies while acknowledging the environmental cost?
</p>

<!-- IMAGE placeholder: Earth at night -->
<!-- <img src="images/your-filename-4.png" alt="Earth at night"> -->

<p>
Even the widespread use of simple applications—cloud storage, online collaboration, video 
streaming—relies on massive server infrastructures. The convenience of the digital era is built 
upon vast invisible environmental consumption.
</p>

<p>
Thinking critically, digital humanities researchers must acknowledge this paradox: While digital 
tools enhance research capabilities, they simultaneously increase our ecological footprint. 
This contradiction requires ethical reflection and long-term solutions.
</p>

<hr>

<h2>3. Bias, misinformation, and the impact of large models on society</h2>

<p>
AI and LLMs do not understand the world—they statistically generate results based on patterns in 
training data. This brings risks: hallucinations, misinformation, biased outputs, and incorrect 
representations of marginalized communities.
</p>

<p>
Although large models appear capable, their errors remind us that they lack genuine comprehension 
and rely on datasets shaped by cultural, social, and political biases. This makes them unreliable 
for tasks requiring deep understanding or ethical judgment.
</p>

<!-- IMAGE placeholder: AI apps -->
<!-- <img src="images/your-filename-5.png" alt="AI apps"> -->

<p>
Meanwhile, prejudice embedded in training data may cause models to misrepresent groups or 
reinforce stereotypes. When misinformation spreads through AI-generated content, the public's 
ability to distinguish truth becomes increasingly challenged.
</p>

<!-- IMAGE placeholder: Disinformation puzzle -->
<!-- <img src="images/your-filename-6.png" alt="Disinformation puzzle image"> -->

<p>
In the digital humanities field, understanding these limitations is crucial. Scholars must rethink 
the use of AI tools and establish mechanisms ensuring transparency, reliability, and critical 
engagement with machine-generated content.
</p>

<hr>

<h2>Conclusion</h2>

<p>
Through this semester’s exploration of digital technology and large models, I now understand that 
the convenience of the digital era is built upon hidden costs. These include environmental damage, 
resource exploitation, energy consumption, and knowledge biases.
</p>

<p>
First, intelligent technologies rely on rare materials and global labour systems. Second, their 
operation consumes substantial energy and creates environmental pressures. Third, LLMs produce 
inaccurate and biased information, impacting public understanding and knowledge reliability.
</p>

<p>
Recognizing these factors helps digital humanities researchers critically engage with technology 
and develop responsible approaches to digital scholarship.
</p>

<!-- IMAGE placeholder: Getty image -->
<!-- <img src="images/your-filename-7.png" alt="Diverse hands united"> -->


<hr>

<h2>References</h2>

<p>Aerps.com (2025) AI apps. [Photograph] Available at: (Accessed: 3 December 2025).</p>
<p>Baumeister (2021) Global supply chain. [Image].</p>
<p>Crawford, K. & Joler, V. (2018) Anatomy of an AI System.</p>
<p>FlyD (2021) Cybersecurity image. [Photograph].</p>
<p>Getty Images (2024) Diverse hands joined in unity. [Photograph].</p>
<p>Samoyedness (2021) Exploitation of resources. [Image].</p>
