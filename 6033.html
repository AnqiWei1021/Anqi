<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>In the Digital Humanities Era of AI: Reflection From Global Resources to Risks of Large Models</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>

    <!-- 顶部标题区 -->
    <header class="site-header">
        <h1 class="title">Anqi Wei, MA – Digital Arts & Humanities</h1>
        <p class="subtitle">A student & creative thinker</p>

        <nav class="navbar">
            <a href="index.html">Home</a>
            <a href="portfolio.html">Portfolio</a>

            <div class="dropdown">
                <span class="dropbtn">Writing ▼</span>
                <div class="dropdown-content">
                    <a href="6033.html">DH6033 – Conceptual Introduction to DAH</a>
                    <a href="6013.html">DH6013 – Graduate Research and Generic Skills</a>
                    <a href="6032.html">DH6032 – Communities of Practice in Digital Scholarship</a>
                    <a href="6006.html">DH6006 – Teaching and Learning in DH</a>
                    <a href="6012.html">DH6012 – Publishing & Editing</a>
                </div>
            </div>
        </nav>
    </header>

    <!-- 写作内容区域 -->
       <main class="writing-container">

    <!-- ===== 顶部信息（左对齐） ===== -->
    <div class="writing-meta">
        <p>Anqi Wei 125101394</p>
        <p>DH6033: Conceptual Introduction to Digital Arts and Humanities</p>
        <p>Lecturer: Órla Murphy</p>
        <p>Last Updated: 2025-12-05</p>
    </div>

    <!-- ===== 居中大标题 ===== -->
    <h1 class="writing-title center-title">
        In the Digital Humanities Era of AI: Reflection From Global Resources to Risks of Large Models
    </h1>

    <!-- ===== 顶部图片 ===== -->
    <figure class="writing-figure">
    <img src="images/earth-night.jpg"
     alt="Earth at night"
     style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>Earth at night (NASA, 2015)</figcaption>
</figure>


    <!-- ===== 正文开始（Introduction）===== -->
    <div class="writing-content">

        <h2>Introduction</h2>
        <p>In the digital era, people often describe digital technology as efficient, convenient, and dematerialized. However, in 2025, I participated in the course of DH6033: Conceptual Introduction to Digital Arts and Humanities, and I gradually realized that digital technology is more complex than our imagination. The operation of digital technology is deeply dependent on a huge material infrastructure, an enormous amount of energy resources, and also company bring some risks of society and ethics. Actually, digital technology is not detached from the real world; in contrast, it is deeply involved in all aspects of the environmental system, labor relationship, and creates knowledge. When people discuss AI, they prefer to emphasize its algorithmic ability, calculation efficiency, and technology innovation, and ignore the real conditions behind AI. This includes continuous consumption of energy in large data centers, the exploitation of mineral resources, the cost of labor in the global manufacturing chain, and the complex supply system to support its operation. Meanwhile, digital humanities are often seen as a research activity of knowledge and culture. With the rapid development of digital technology, it more deeply relies on digital infrastructure, and it also brings the issue of environmental and resource consumption cannot be ignored. </p>
        <p>Therefore, this article will conduct reflections from three interrelated levels:</p>

<ul>
    <li><strong>
        Understand that the operation of AI relies on the exploitation of resources,
        collected data, and the global supply chain.
    </strong></li>

    <li><strong>
        Discuss how digital technology brings energy consumption and environmental
        issues, rethinking how digital humanities can reduce its influence.
    </strong></li>

    <li><strong>
        Analyze how large models may bring biases, misinformation, and their impact
        on society and knowledge production.
    </strong></li>
</ul>
<p>I hope that this article can remind us that in the digital humanities era, we cannot only see the convenience that AI technology brings, but also need to focus on the aspects of ethics, the environment, and its influence on the system.</p>
<h2>The operation of AI relies on the exploitation of resources, collected data, and the global supply chain.</h2>

        <hr class="section-divider">
        
<p>
Before reading the article <em>“Anatomy of an AI System” (Crawford & Joler, 2018)</em>, 
my understanding of AI devices still stayed on the surface layer. They are convenient, 
intelligent, and can help me complete some simple instructions, such as in China 
“XiaoAi Classmates” by <em>Xiaomi</em> Corporation, which seems popular as Echo by Amazon, 
like turning on the light or turning off the light, playing a video, and so on. 
However, I had never thought about where these devices come from and how they operate. 
This article straightforwardly showed me that behind all seems smart and convenient 
functions, there is a huge material investment in the real world.
</p>
<p>
First, about the exploitation of resources. Intelligent devices need batteries, chips, 
and sensors etc., all of which rely on earth-limited and non-renewable materials, such as 
Lithium, Cobalt, and rare earth elements <em>(Crawford & Joler, 2018)</em>. Before, I just 
thought that intelligent devices were becoming cheaper, but I never realized that behind 
this cheapness is the Earth’s resources have been accelerated exploitation and consumption. 
The anatomy of this article made me realized that whether Echo or XiaoAi Classmates, they 
all rely on a supply chain built on the Earth’s resources, and this exploitation not only 
damages ecology but also does not conform to the principle of sustainable development. We 
pursue a smart lifestyle, yet we are seriously hiding the costs of environmental damage and 
resource damage.
</p>
        <figure class="writing-figure">
    <img src="images/exploitation.jpg" alt="Exploitation of resources"
         style="width:100%; max-width:1000px; display:block; margin:auto;">
    <figcaption style="margin-top:10px; font-size:14px; text-align:center;">
        Exploitation of resources (<em>Samoyedness, 2021</em>)
    </figcaption>
</figure>
<p>Second, about the data and privacy. When an AI device carries out our instructions, it will also continuously record and analyze users’ daily behavior data, like work and rest schedules, voice content, interest preferences, family activity patterns, etc. This data is usually collected in the background, and these data will connect to the cloud, where it is uploaded, stored, and further processed. They are not only applicable in response to the users’ instructions, but also will be used in training models and the construction of user profiles. In this structure, users’ details of life will be systematically transformed into computable data assets. Privacy is transferred from individuals to technical systems, the device records voice, usage time, and background sounds can be used to infer users’ emotions, lifestyles, and family conditions, and these analyses can often not be found by users, even find it, users cannot understand what this function. This leads to intelligence devices understanding users more, and users' control over their own data rights will be weakened, and the privacy boundary will also be redefined by technology.</p>
<figure class="writing-figure">
    <img src="images/cybersecurity.jpg"
         alt="Cybersecurity image"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>Cybersecurity image (FlyD, 2021)</figcaption>
</figure>
<p>Third, about the global supply chain. There are many has been ignored environmental costs of the manufacturing of an AI device and transportation. For instance, to reduce the transportation costs, most of the container shipping companies use very low grade fuel in enormous quantities, and in the raw material processing stage, "After refining one ton of rare earth elements, approximately 75 cubic meters of acidic waste water and about one ton of radioactive waste residue are produced" (Crawford & Joler, 2018). These data indicate that there are direct material relationship between intelligent devices, ocean pollution, and chemical emissions, and this relationship has been hidden in our daily consumption experiences. Put these realities together with the Amazon Echo or XiaoAi Classmates, and we can see an obvious contrast is that the intelligent device more smaller, but behind its production and transportation process is maybe more complex.</p>
    <figure class="writing-figure">
    <img src="images/global-supply-chain.jpg"
         alt="Global supply chain"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>Global supply chain (Baumeister, 2021)</figcaption>
</figure>
        <hr class="section-divider">

<h2>Digital technology brings energy consumption and environmental issues,
rethinking how digital humanities can reduce its influence.</h2>
<p>After understanding the material structure behind intelligent devices, the Digital Humanities Climate Coalition Toolkit (DHCC) and Stochastic Parrots made me understand another important layer is that digital technology itself also depends on a continuous investment of energy. The DHCC mentioned, “Any system running online is connected to power-hungry servers, data centres, and hardware update cycles. The digital does not mean lightweight or low cost; conversely, the larger the digital infrastructure, the higher its energy and resource demand.” (Digital Humanities Climate Coalition, 2025). This perspective complements the understanding in the previous text, and shows that intelligent technology cannot only focus on the device itself; instead, it also needs to include the wider digital environment that supports the device’s normal operation. The intelligent device function needs support from resources, labor, and data, and these data’s processing, storage, and training models also need a large amount of energy. Thus, the issue is not just limited to the device layer, but it extends to the whole operation ways of digital technology, with the technological intervention having been deepening continuously, environmental and privacy impact must be faced as issues, and clarifying these impacts will help us to redefine the significance of intelligent technology.</p>
<figure class="writing-figure">
    <img src="images/dhcc-logo.png" 
         alt="Digital Humanities Climate Coalition logo"
         style="width:100%; max-width:800px; display:block; margin:auto;">
    <figcaption>Digital Humanities Climate Coalition logo (DHCC, 2025)</figcaption>
</figure>
<p>Bender et al. (2021) argue that global data centers need a large amount of power to support the servers working, as well as need immense quantities of water to cool the machines to prevent them from overheating. When we scan a photo, watch a short video, or submit a search request, we all will consume some energy, especially after seeing the consumption data of large models, I gradually came to know my previous judgment on the digital technologies' energy was not comprehensive enough. For example, the Stochastic Parrots reports that training a big transformer model approximately produces 284t of CO2, close to the total emissions of a person's lifetime (Bender et al., 2021). This data is so shocking because it means a normal AI-generated request needs an extremely energy-consuming computing process. Actually, it does not just happen in the training models, even when models are in the stage of inference also continuously consume energy (like ChatGPT or DeepSeek’s daily conversation), and it also reminds me that every question posed to AI will consume a certain of energy and computing resources, and it is not a cost-free operation.</p>
    <figure class="writing-figure">
    <img src="images/power-towers.jpg"
         alt="Power transmission towers over water"
         style="width:100%; max-width:1000px; display:block; margin:auto;">
    <figcaption>Power transmission towers over water (Fang, 2023).</figcaption>
</figure>
<p>This also made me reflect on my own habits when using digital technologies. In the past, when I was in contact with digital content or digital platforms, I often thought that the more functions a system has, the better it is, such as a high-definition picture or complex animation, so I prefer to think "The more you do, the better it is". But I never realized that these design in the servers means more computing, storage, transmission, and energy consumption. When I visit large-scale exhibitions or online museums, I focus only on their visual presentation, but I ignore how much water and electricity are required behind this content. In fact, if a digital exhibition includes a number of high-definition images, 3D models, or long videos, it may have more burden than a physical exhibition. So digitalization does not necessarily equal environmental protection; it just makes resource consumption occur in a position that users usually cannot see. As users, we should not only focus on the efficiency of the tool, but also should consider behind it the energy cost, and the source of the training data, and the environmental burden brought about by its continuous operation.</p>
   <p>The DHCC Toolkit (2025) has proposed many specific sustainable practices, which have had a significant inspiration to me. Such as:</p>

<ul>
    <li>Minimize client-side operations (scripts, animations) and energy-intensive server calls.</li>
    <li>Optimize images, compress file sizes, and avoid excessive high definition.</li>
    <li>Use static site generators where appropriate to minimize database reliance (like Jekyll, HUGO).</li>
    <li>Use carbon measurement tools to estimate the energy consumption of your project before development.</li>
</ul>

<p>These suggestions made me realize that as digital humanities students, we not only consider how to make a beautiful work, but also need to think about how to create a sustainable work. I began to rethink the value of the digital humanities project; it's not a simple technology operation, it’s a practice connected to resource utilization, energy consumption, and data processing. While pursuing knowledge, we also need to understand the material conditions and environmental costs of digital technology operation, which will help us to comprehensively know the real impact of digital humanities work.</p>
 <hr class="section-divider">

<h2>The large language models’ bias, misinformation, and their impact on society and knowledge production. </h2>
    <p>AI technology brought risks not only at the industrial chain and environmental levels, but also exists in the language output itself. Large Language Models (LLMs) have been seen as the most influential tools of digital technology. They can generate natural language, summarize information, write code, and even replace human judgment in some scenarios. However, when I read the article “Stochastic Parrots: Can Language Models Be Too Big?” by Bender et al., I re-examined the intelligence of LLMs and also found that they may include more bias and misleading information than I previously understood. The article's most important point is to describe large models as "stochastic parrots", and these models do not really understand human language; they just rely on statistical probability to forecast the next most likely word to appear (Bender et al., 2021). Which means that generated AI can output many seemingly natural language, actually, it cannot understand the language's meaning, just because it learn the language’s external form from many texts. In other words, the fluency of language comes from statistical results, not from the ability of the model to understand.</p>
    <figure class="writing-figure">
    <img src="images/ai-apps.jpg"
         alt="AI apps displayed on a smartphone"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>AI apps displayed on a smartphone (Aerps.com, 2025).</figcaption>
</figure>
<p>In fact, I also have an AI experience. About a month ago, when I asked DeepSeek about the details of the French visa policy, it gave me an answer that looked so good, clear structure and a rigorous tone, and it seemed to come from an official source. But when I try to compare this content with the official website of the French Embassy, I found that the information provided by the models doesn’t have source support, and also does not actually exist. I began to realize that the language models, even without real evidence it can generate seemingly credible content, and users often cannot immediately judge whether the answer is correct. The example mentioned in “stochastic parrots” further reinforces this understanding: “a Palestinian man who posted ‘good morning’ on Facebook and had it automatically translated to ‘attack them’, resulting in his arrest and subsequent questioning by police.” (Bender et al., 2021, p. 618). This incident indicates that language models’ mistakes not only may influence our personal judgment, but they also may affect fields such as law enforcement, healthcare, education, or policy. Combined with my own experience, language models’ issues include error technology, and distribution of judgment, trust, and responsibility. When we rely on a model that provides information, how can we identify its reliability, and how can to make a judgment in an uncertain situation?</p>
    <p>Meanwhile, the prejudice issue of large models is equally worrying. Most language databases for training models come from the internet, but the internet itself is full many prejudices, such as sex stereotypes, racism, and class discrimination etc. Therefore, the model not only absorbs these biases but may also amplify them when generating language, which leads to the content generated not being objective, neutral, because its output will be influenced by training data, development method, or algorithm mechanism factors, while when people use content generated by AI, these prejudices will continue to be disseminated and influence the new knowledge formation. The impact this has on society and knowledge systems is complex; the prejudice of AI is not alone, it reflects the world's unequal structure, when large models have been used in scenarios such as news generation, recruitment screening, intelligence assessment, and cultural communication, they may reinforce the inequality in society, especially for minority language communities, non-popular cultures, or marginalized groups, due to them appear in language databases proportion is very low, models often cannot correct understanding, thus leading to neglect or misunderstanding.</p>
<figure class="writing-figure">
    <img src="images/disinformation.jpg"
         alt="Disinformation puzzle concept image"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>“Disinformation” puzzle concept image (Shuper, 2024).</figcaption>
</figure>
<p>Finally, in the area of digital humanities, the limitations of large models are particularly worthy of attention. Digital humanities focus on how established the knowledge is, but also focus on how culture is understood. If researchers use large models that cannot check the information source, and cannot critically think about content generated by the AI, it will lead to models’ prejudice, and fictional content will enter academic discussion, and influence research direction, even leading us to produce some bias in understanding history and culture. Overall, large models are not only technical tools; they also have social and cultural impacts. They can help us to improve our work or study efficiency, but also it can also deepen the existing issues; they can accelerate knowledge generation, but they can also spread misinformation more quickly. In this situation, understanding the large models’ prejudices and mechanisms is very necessary for digital humanities researchers.</p>
 <hr class="section-divider">
        <h2>Conclusion</h2>
        <p>Through this semester's study of digital technology and the system, I gradually realized that digital technology is never a technology alone; in contrast, its operation relies on resource exploitation, energy consumption, and a huge supply chain, and also influences knowledge production and social structure. This article reflects on three aspects: The AI’s operation relies on resource exploitation, the environmental pressure from digital technology, and the risks of large models. Overall, these factors reflect a key fact that the convenience of the digital era has a huge invisible cost.</p>
    <p>
First and foremost, we cannot ignore the intelligent technologies' material base.
<i>“Anatomy of an AI System”</i>, this article made me refreshed on the supply system of
intelligent devices, exploitation of scarce minerals, complex manufacturing process,
large-scale logistics transportation, and continuous data collection are all
preconditions supporting intelligent function normal operation. These realities are
usually hidden in advertising language, but resources are destroyed, labor investment,
and environmental issues are real exist, which means that we cannot just notice
intelligent devices are convenient, but also need to rethink behind resource
consumption and environmental issues.
</p>
        <p>Second, the digital technologies’ operation needs huge energy support. The DHCC Toolkit (2025) points out <i>“the digital is material.” </i>
            In reality, although digital humanities projects are often seemingly in an environmental protection knowledge practice, but they rely on servers, high-definition images, 3D models, or long videos, all continuously consume large amounts of electricity and cooling resources. So, digital humanities are not originally very environmentally friendly, and how reducing unnecessary calculations, reducing file size, using static pages, and considering the lifecycle of web pages becomes the responsibility of digital humanities researchers.</p>
    <p>Third, the prejudiced and mistaken information of LLMs will impact the knowledge production and social structure. Bender et al. (2021) stated that LLMs cannot really understand language; they just depend on statistical probability to generate fluent text. Which means that models may confidently draw up information without any basis, and users cannot find this issue. I was once misled by a wrong answer about French visa information, and Bender gives an example also showing that the models’ incorrect translation may bring some serious outcomes. Meanwhile, due to the training model itself having prejudice, and large models can also replicate or even amplify these biases in their outputs, which impacts knowledge reliability.</p>
    <p>In conclusion, in the digital humanities age, the application of technology is not a choice of tools; it must face complex responsibilities of resources, energy, data, ethics, and social impact. As a student in a digital humanities major, I need to think deeply about how these technologies operate and think about the costs and impacts behind them. In the future, I hope I have a more responsible attitude and reflective ways to create digital projects, rather than only pursuing complex and novel ones, which may be the most important ability in the digital era.</p>
    <figure class="writing-figure">
    <img src="images/hands-unity.jpg"
         alt="Diverse hands joined in unity"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>Diverse hands joined in unity (Getty Images, 2024).</figcaption>
</figure>
  <hr class="section-divider">
        <h2>References</h2>
    <ul class="reference-list">
<li>
    Aerps.com (2025) <em>Ai apps.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-hand-holds-a-smartphone-with-various-apps-P5sGqNT_Aj8" target="_blank">
        A hand holds a smartphone with various apps. photo – Free Artificial Intelligence Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
<li>
    Bender, E.M., Gebru, T., McMillan-Major, A. and Shmitchell, S. (2021)
    ‘On the dangers of stochastic parrots: Can language models be too big?’,
    <i>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’21)</i>,
    pp. 610–623. Available at:
    <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank">
        https://dl.acm.org/doi/10.1145/3442188.3445922
    </a>
    (Accessed: 1 Dec 2025).
</li>
<li>
    Baumeister, M. (2021) <em>Global Supply Chain.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-tug-boat-pulling-a-large-container-ship-3XjMwxUHx0Q" target="_blank">
        A tug boat pulling a large container ship photo – Free Boat Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        <li>
    Crawford, K. & Joler, V. (2018) <em>Anatomy of an AI System: The Amazon Echo as an anatomical map of human labour, data and planetary resources.</em> 
    Published by SHARE Lab, SHARE Foundation and The AI Now Institute, NYU. Available at: 
    <a href="https://anatomyof.ai/" target="_blank">
        Anatomy of an AI System
    </a>
    (Accessed: 20 Nov 2025).
</li>
<li>
    Digital Humanities Climate Coalition (2025) <em>Digital Humanities Climate Coalition Toolkit.</em> 
    Available at: 
    <a href="https://sas-dhrh.github.io/dhcc-toolkit/" target="_blank">
        Home | DHCC Toolkit
    </a>
    (Accessed: 1 Dec 2025).
</li>
    <li>
    FlyD (2021) <em>Cybersecurity image.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/purple-and-pink-light-illustration-C5pXRFEjq3w" target="_blank">
        Purple and pink light illustration photo – Free Green Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
        <li>
    Fang, C. (2023) <em>Power transmission towers over water.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-couple-of-power-poles-sitting-in-the-middle-of-a-body-of-water-JZ_nEBZ1BJs" target="_blank">
        A couple of power poles sitting in the middle of a body of water photo – Free China Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
<li>
    Getty Images (2024) <em>Diverse hands joined in unity.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/diverse-multiethnic-partners-hands-together-teamwork-group-of-multiracial-people-meeting-join-hands-togetherness-diversity-people-hands-join-empower-partnership-teams-connection-volunteer-community-gvY023x2CRA" target="_blank">
        Diverse hands joined in unity – Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
<li></li> 
        
<li></li>
    </div>
</main>

    
