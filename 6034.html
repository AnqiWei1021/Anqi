<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>In the Digital Humanities Era of AI: Reflection From Global Resources to Risks of Large Models</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- 顶部标题区 -->
    <header class="site-header">
        <h1 class="title">Anqi Wei, MA – Digital Arts & Humanities</h1>
        <p class="subtitle">A student & creative thinker</p>

        <nav class="navbar">
            <a href="index.html">Home</a>
            <a href="portfolio.html">Portfolio</a>

            <div class="dropdown">
                <span class="dropbtn">Writing ▼</span>
                <div class="dropdown-content">
                    <a href="6034.html">DH6034 — Humanities and New Technologies: Tools and Methodologies</a>
                    <a href="6033.html">DH6033 – Conceptual Introduction to DAH</a>
                    <a href="6013.html">DH6013 – Graduate Research and Generic Skills</a>
                    <a href="6032.html">DH6032 – Communities of Practice in Digital Scholarship</a>
                    <a href="6006.html">DH6006 – Teaching and Learning in DH</a>
                    <a href="6012.html">DH6012 – Publishing & Editing</a>
                </div>
            </div>
        </nav>
    </header>
 <!-- 写作内容区域 -->
       <main class="writing-container">

    <!-- ===== 顶部信息（左对齐） ===== -->
   <div class="my-info">
    <p>Anqi Wei 125101394</p>
    <p>DH6034: Humanities and New Technologies: Tools and Methodologies</p>
    <p>Lecturer: Dr.</p>
    <p>Last Updated: 2026-02-26</p>
</div>
           <!-- ===== 居中大标题 ===== -->
    <h1 class="writing-title center-title">
        Community Engaged Crowdsourcing: My Experience with Irish Weather Rescue
    </h1>


    <!-- ===== 正文开始（Introduction）===== -->
    <div class="writing-content">

        <h2>Introduction</h2>
        <p>In this assignment, I participated in the project called Irish Weather Rescue on the platform of Zooniverse. This project mainly focuses on transcribing the handwritten rainfall records of the 20th century to support the reconstruction of Ireland’s historical climate data. During my participation, I selected the 20S Dublin Data 2 section and completed the transcription of daily rainfall records from the periods 1920-1923 and 1926-1929. A total of 99 months of rainfall information has been entered. This article will reflect on the specific process of my participation in the Irish Weather Rescue crowdsourcing project, including the importance of my contribution to the project goals, and the wider value of crowdsourcing practice to academic research and the social level, and will pay attention to the ethical issues involved. Finally, I will reflect on my personal gains from this crowdsourcing practice and explore how this experience influences my future academic work.</p>

<hr class="section-divider">
        <h2>Process</h2>

     
        
<p>
Before engaging in the crowdsourcing task, I first explored many different types of crowdsourcing projects on the Zooniverse platform, and finally chose Irish Weather Rescue. The reason why I chose this project is, on the one hand, that I have always been curious about Ireland’s rainy climate characteristics, and I hoped that through this practice better understand this phenomenon; on the other hand, the project takes the transcription of handwritten rainfall data from the 20th century as its main task, which strongly related to typical digital humanities archival work. After completing the account sign-out and carefully reading the tutorial and field guide provided by the project, I entered the 20S Dublin Data 2 Section and officially began to transcribe historical rainfall records month by month.
</p>
<p>
During the transcription process, I mainly followed the platform’s instructions to enter the monthly daily rainfall data. To be specific, first, I need to identify the handwritten value of the corresponding month, and then accurately enter it into the system table; for dates marked in blank or with dashes, leave them blank according to the specifications. At the same time, I also need to fill in the per month total rainfall, and judge whether there are any changes or unsual situation on the page, if necessary, make notes in the additional remarks column. Through this process, I have gradually completed the systematic transcription work for several years.
</p>
<p>Several practical difficulties emerged during the transcription process. For instance, in some of the records from 1923, 1928, and 1929, there are obvious change traces, which require me to carefully judge through enlarge image and repeated comparisons. In the case of incomplete determination, I choose to leave it blank or add additional remarks according to the project guide to reduce the risk of misrecording. This experience not only improved my patience and attention to historical data but also made me realize that in crowdsourced transcription, the quality of judgment of individual volunteers will directly affect the data’s reliability. Therefore, the participants themselves play an important role in the whole data production chain (Hawkins et al., 2019).</p>

<h2>Implications of My Contribution</h2>
<p>In this task, I have completed a total of 99 months of rainfall data entry. Although this represents only a small portion of the overall project, my participation made me realize that each individual transcription contributes to the integrity of Ireland’s historical climate database, which reflects many small scales contribution will support large-scale digital humanities datasets (Ridge, 2014). When dealing with handwritten meteorological records from a hundred years ago, I clearly felt the importance of manual judgment. These records were written day by day, and there are many places that have traces of post-correction and modification. Therefore, when identifying numbers with traces, it is often necessary to repeatedly enlarge the image and make comparisons before a relatively reliable judgment can be made. Through this process, it made me understand that at present, such detailed recognition work still cannot be completely relied on machines or automated tools, because some ambiguous situations still require human experience for judgment (Ridge, 2014). In this sense, although the crowdsourced work of volunteers may seem repetitive or routine, they play an important role in the product data processing. </p>
<p>From another perspective, the value of crowdsourcing projects does not only lie in organizing or transcribing the historical data itself, but it also slowly changes the participatory ways of digital humanities research. In recent years, many crowdsourcing platforms have occurred on the Internet, such as Zooniverse, Smithsonian Digital Volunteers, and iNaturalist… they encourage the public to directly participate in the processing of various cultural and historical materials. In this environment, many non-professional participants can directly enter the process of recording historical or interesting data, which no longer relies on a traditional research institution or professional guidance. As Ridge (2014) notes, <em>“Asking members of the public to help with tasks can be hugely productive.”</em> I found this openness particularly meaningful. On the one hand, participants can flexibly choose a project based on their personal interests, and in practice, gradually understand the meaning of historical data; on the other hand, these platforms also make it easier for the general public to participate in academic-related work. Personally, this experience itself is attractive and interesting, because it allowed me for the first time to truly work hands-on with original meteorological records from over a hundred years ago. This participatory model, to a certain extent, promotes digital humanities development. It not only expands the human resource base for data processing, but it also narrows the distance between the general public and history; it makes some remote or closed historical records gradually transform into digital resources that can be jointly participated in and understood.</p>
<p>However, in the actual processing, I also gradually realize that the crowdsourcing model itself is not limited. First, different volunteers have different standards when they read handwritten materials, and judging fuzzy data may not be completely consistent. For example, a handwritten “3” might reasonably be read by another volunteer as an “8” or even a “4”. When I was dealing with some records from 1923, 1928, and 1929, I encountered many situations that required subjective judgment. If subjective judgment was wrong, it could indeed influence the quality of subsequent data. And then, such projects mainly rely on the free participation of volunteers (Causer and Wallace, 2012), which also made me rethink the relationship between the voluntary contribution and digital labour. Although many participants are motivated primarily by interest and learning, in the long term, how the platform controls quality and participation incentives is still a question. Therefore, I think it is also necessary to maintain a certain critical understanding of its potential risks while affirming the positive promoting effect of crowdsourcing on climate research and digital humanities.</p>

<h3>What I learned
<p>Through the joint crowdsourcing project of Irish Weather Rescue, I have become more familiar with the detailed operation, and also better understood how crowdsourcing works. The most direct changes are reflected in the specific operation level. When I first began to enter these handwritten rainfall records, I did not have much confidence, especially when encountering pages where the handwriting is blurred, modified, or the table format is not clear, which often needed me to repeatedly check to make a judgment. However, with the number of transcriptions increasing, I began to use some strategies, such as amplification, line-by-line comparison, and repeated checking of data, and the whole entry processing became smoother. This experience trains my patience to observe detail in large extent. Meanwhile, I gradually realized that the foundation data entry plays an important role in the digital humanities project.</p>
<p>In the specific operation processing, one experience has a particularly obvious impact on me. While working on records from around 1921, I noticed that the original table format is not clear, and then some of the data itself is a little fuzzy. To address this, I tried to visually divide the auxiliary line by myself and partitioned the data of the three months into groups, which helped me enter the numbers more quickly and accurately. At first, I did this just to make it easier for me to see the data clearly. But as the transcription progressed, I realized that these historical records themselves were not as "standard" as I had imagined; in some cases, the readability of the data still requires manual organization, and it cannot completely rely on the interface itself.</p>
<p>As I continued transcribing, I also encountered another situation deep impact me. In the case of the 1920 rainfall records, the Zooniverse platform provides me with two different versions of the page: in the first version, only the December rainfall data is recorded, January to November are blank; and in the second version provides a complete record for the whole year. What makes me even more confused is that two versions of the data for December are not coincide. This difference made me not sure how to understand it, and also made me think about why two different data versions appear in the same year; moreover, there are obvious differences between the two. Combine my judgment with crowdsourcing, some participants perhaps face is not always a fully cleaned and unified data source; historical archives may have different versions in the process of preservation and digitization. </p>
<p>Baes on these specific experiences, my understanding on crowdsourcing transcription work have some change. Human participants in crowdsourcing work are not just mechanical input data; rather, they continue to participate in identifying, cleaning, and judging data structures, especially when they deal with some fuzzy pages, they play an important role in the data transcription (Lintott et al., 2008). From this perspective, crowdsourcing is not only an efficiency tool, but also it is a collaborative way of knowledge production. However, this model is also risky: different volunteers have different standard to fuzzy numbers, and this difference may affect the data reliability. In general, this experience made me better understand the potential and limitations of crowdsourcing in digital humanities research.</p>

<h3>Application to my own work
<p>In the practice of Irish Weather Rescue, I begin to specifically think about how these transcription experiences influence my study and future research. For my current study in digital humanities, I no longer understand digital process from theoretical level; now I will pay more attention to the process of sorting, judging, and quality control of the data before entering the analysis stage. In the past, when I was exposed to digital humanities in the classroom, I always focused on digital tools and data outcomes, but this practice made me realize that the early stage of data production also has decisive significance. In the future, when processing historical data or materials, I will actively pay more attention to the reliability of data sources and some potential human errors.</p>
<p>For a long-term perspective, this experience also made me start to seriously think, in the future, how to use a practical crowdsourcing method in my own research project. For instance, when dealing with some basic statistical tasks, I can also consider using crowdsourcing to publish some online tasks and recruit some volunteers to participate in completing the data processing. In the process, I will take extra notice on operation guide to reduce some human error. Meanwhile, I also consider whether it was necessary to add a manual review or data comparison to improve data reliability.</p>
<p>At the same time, I began to gradually realize that digital humanities not just use technology to process data, but also like establishing a connection between historical materials, digital platforms, and the general public. Projects like Irish Weather Rescue made me directly see how digital humanities through digital platforms connected public and academic data production. Based on this experience, I will pay more attention to the interactive ways between the platform, data, and the public. In summary, this practical experience changed my original imagine on the way of digital humanities, it is more open, inclusive, and diverse.</p>


    
    <ul>
    <li>Minimize client-side operations (scripts, animations) and energy-intensive server calls.</li>
    <li>Optimize images, compress file sizes, and avoid excessive high definition.</li>
    <li>Use static site generators where appropriate to minimize database reliance (like Jekyll, HUGO).</li>
    <li>Use carbon measurement tools to estimate the energy consumption of your project before development.</li>
</ul>

<p>These suggestions made me realize that as digital humanities students, we not only consider how to make a beautiful work, but also need to think about how to create a sustainable work. I began to rethink the value of the digital humanities project; it's not a simple technology operation, it’s a practice connected to resource utilization, energy consumption, and data processing. While pursuing knowledge, we also need to understand the material conditions and environmental costs of digital technology operation, which will help us to comprehensively know the real impact of digital humanities work.</p>
 <hr class="section-divider">

<h2>The large language models’ bias, misinformation, and their impact on society and knowledge production. </h2>
    <p>AI technology brought risks not only at the industrial chain and environmental levels, but also exists in the language output itself. Large Language Models (LLMs) have been seen as the most influential tools of digital technology. They can generate natural language, summarize information, write code, and even replace human judgment in some scenarios. However, when I read the article “Stochastic Parrots: Can Language Models Be Too Big?” by Bender et al., I re-examined the intelligence of LLMs and also found that they may include more bias and misleading information than I previously understood. The article's most important point is to describe large models as "stochastic parrots", and these models do not really understand human language; they just rely on statistical probability to forecast the next most likely word to appear (Bender et al., 2021). Which means that generated AI can output many seemingly natural language, actually, it cannot understand the language's meaning, just because it learn the language’s external form from many texts. In other words, the fluency of language comes from statistical results, not from the ability of the model to understand.</p>
    <figure class="writing-figure">
    <img src="images/ai-apps.jpg"
         alt="AI apps displayed on a smartphone"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>AI apps displayed on a smartphone (Aerps.com, 2025).</figcaption>
</figure>
<p>In fact, I also have an AI experience. About a month ago, when I asked DeepSeek about the details of the French visa policy, it gave me an answer that looked so good, clear structure and a rigorous tone, and it seemed to come from an official source. But when I try to compare this content with the official website of the French Embassy, I found that the information provided by the models doesn’t have source support, and also does not actually exist. I began to realize that the language models, even without real evidence it can generate seemingly credible content, and users often cannot immediately judge whether the answer is correct. The example mentioned in “stochastic parrots” further reinforces this understanding: “a Palestinian man who posted ‘good morning’ on Facebook and had it automatically translated to ‘attack them’, resulting in his arrest and subsequent questioning by police.” (Bender et al., 2021, p. 618). This incident indicates that language models’ mistakes not only may influence our personal judgment, but they also may affect fields such as law enforcement, healthcare, education, or policy. Combined with my own experience, language models’ issues include error technology, and distribution of judgment, trust, and responsibility. When we rely on a model that provides information, how can we identify its reliability, and how can to make a judgment in an uncertain situation?</p>
    <p>Meanwhile, the prejudice issue of large models is equally worrying. Most language databases for training models come from the internet, but the internet itself is full many prejudices, such as sex stereotypes, racism, and class discrimination etc. Therefore, the model not only absorbs these biases but may also amplify them when generating language, which leads to the content generated not being objective, neutral, because its output will be influenced by training data, development method, or algorithm mechanism factors, while when people use content generated by AI, these prejudices will continue to be disseminated and influence the new knowledge formation. The impact this has on society and knowledge systems is complex; the prejudice of AI is not alone, it reflects the world's unequal structure, when large models have been used in scenarios such as news generation, recruitment screening, intelligence assessment, and cultural communication, they may reinforce the inequality in society, especially for minority language communities, non-popular cultures, or marginalized groups, due to them appear in language databases proportion is very low, models often cannot correct understanding, thus leading to neglect or misunderstanding.</p>
<figure class="writing-figure">
    <img src="images/disinformation.jpg"
         alt="Disinformation puzzle concept image"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>“Disinformation” puzzle concept image (Shuper, 2024).</figcaption>
</figure>
<p>Finally, in the area of digital humanities, the limitations of large models are particularly worthy of attention. Digital humanities focus on how established the knowledge is, but also focus on how culture is understood. If researchers use large models that cannot check the information source, and cannot critically think about content generated by the AI, it will lead to models’ prejudice, and fictional content will enter academic discussion, and influence research direction, even leading us to produce some bias in understanding history and culture. Overall, large models are not only technical tools; they also have social and cultural impacts. They can help us to improve our work or study efficiency, but also it can also deepen the existing issues; they can accelerate knowledge generation, but they can also spread misinformation more quickly. In this situation, understanding the large models’ prejudices and mechanisms is very necessary for digital humanities researchers.</p>
 <hr class="section-divider">
        <h2>Conclusion</h2>
        <p>Through this semester's study of digital technology and the system, I gradually realized that digital technology is never a technology alone; in contrast, its operation relies on resource exploitation, energy consumption, and a huge supply chain, and also influences knowledge production and social structure. This article reflects on three aspects: The AI’s operation relies on resource exploitation, the environmental pressure from digital technology, and the risks of large models. Overall, these factors reflect a key fact that the convenience of the digital era has a huge invisible cost.</p>
    <p>
First and foremost, we cannot ignore the intelligent technologies' material base.
<i>“Anatomy of an AI System”</i>, this article made me refreshed on the supply system of
intelligent devices, exploitation of scarce minerals, complex manufacturing process,
large-scale logistics transportation, and continuous data collection are all
preconditions supporting intelligent function normal operation. These realities are
usually hidden in advertising language, but resources are destroyed, labor investment,
and environmental issues are real exist, which means that we cannot just notice
intelligent devices are convenient, but also need to rethink behind resource
consumption and environmental issues.
</p>
        <p>Second, the digital technologies’ operation needs huge energy support. The DHCC Toolkit (2025) points out <i>“the digital is material.” </i>
            In reality, although digital humanities projects are often seemingly in an environmental protection knowledge practice, but they rely on servers, high-definition images, 3D models, or long videos, all continuously consume large amounts of electricity and cooling resources. So, digital humanities are not originally very environmentally friendly, and how reducing unnecessary calculations, reducing file size, using static pages, and considering the lifecycle of web pages becomes the responsibility of digital humanities researchers.</p>
    <p>Third, the prejudiced and mistaken information of LLMs will impact the knowledge production and social structure. Bender et al. (2021) stated that LLMs cannot really understand language; they just depend on statistical probability to generate fluent text. Which means that models may confidently draw up information without any basis, and users cannot find this issue. I was once misled by a wrong answer about French visa information, and Bender gives an example also showing that the models’ incorrect translation may bring some serious outcomes. Meanwhile, due to the training model itself having prejudice, and large models can also replicate or even amplify these biases in their outputs, which impacts knowledge reliability.</p>
    <p>In conclusion, in the digital humanities age, the application of technology is not a choice of tools; it must face complex responsibilities of resources, energy, data, ethics, and social impact. As a student in a digital humanities major, I need to think deeply about how these technologies operate and think about the costs and impacts behind them. In the future, I hope I have a more responsible attitude and reflective ways to create digital projects, rather than only pursuing complex and novel ones, which may be the most important ability in the digital era.</p>
    <figure class="writing-figure">
    <img src="images/hands-unity.jpg"
         alt="Diverse hands joined in unity"
         style="width:100%; max-width:900px; display:block; margin:auto;">
    <figcaption>Diverse hands joined in unity (Getty Images, 2024).</figcaption>
</figure>
  <hr class="section-divider">
        <h2>References</h2>
    <ul class="reference-list">
<li>
    Aerps.com (2025) <em>Ai apps.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-hand-holds-a-smartphone-with-various-apps-P5sGqNT_Aj8" target="_blank">
        A hand holds a smartphone with various apps. photo – Free Artificial Intelligence Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
<li>
    Bender, E.M., Gebru, T., McMillan-Major, A. and Shmitchell, S. (2021)
    ‘On the dangers of stochastic parrots: Can language models be too big?’,
    <i>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’21)</i>,
    pp. 610–623. Available at:
    <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank">
        https://dl.acm.org/doi/10.1145/3442188.3445922
    </a>
    (Accessed: 1 Dec 2025).
</li>
<li>
    Baumeister, M. (2021) <em>Global Supply Chain.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-tug-boat-pulling-a-large-container-ship-3XjMwxUHx0Q" target="_blank">
        A tug boat pulling a large container ship photo – Free Boat Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        <li>
    Crawford, K. & Joler, V. (2018) <em>Anatomy of an AI System: The Amazon Echo as an anatomical map of human labour, data and planetary resources.</em> 
    Published by SHARE Lab, SHARE Foundation and The AI Now Institute, NYU. Available at: 
    <a href="https://anatomyof.ai/" target="_blank">
        Anatomy of an AI System
    </a>
    (Accessed: 20 Nov 2025).
</li>
<li>
    Digital Humanities Climate Coalition (2025) <em>Digital Humanities Climate Coalition Toolkit.</em> 
    Available at: 
    <a href="https://sas-dhrh.github.io/dhcc-toolkit/" target="_blank">
        Home | DHCC Toolkit
    </a>
    (Accessed: 1 Dec 2025).
</li>
    <li>
    FlyD (2021) <em>Cybersecurity image.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/purple-and-pink-light-illustration-C5pXRFEjq3w" target="_blank">
        Purple and pink light illustration photo – Free Green Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
        <li>
    Fang, C. (2023) <em>Power transmission towers over water.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/a-couple-of-power-poles-sitting-in-the-middle-of-a-body-of-water-JZ_nEBZ1BJs" target="_blank">
        A couple of power poles sitting in the middle of a body of water photo – Free China Image on Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
<li>
    Getty Images (2024) <em>Diverse hands joined in unity.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/diverse-multiethnic-partners-hands-together-teamwork-group-of-multiracial-people-meeting-join-hands-togetherness-diversity-people-hands-join-empower-partnership-teams-connection-volunteer-community-gvY023x2CRA" target="_blank">
        Diverse hands joined in unity – Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
<li>
    NASA (2015) <em>Earth at night.</em> [Photograph] Available at: 
    <a href="https://unsplash.com/photos/photo-of-outer-space-Q1p7bh3SHj8" target="_blank">
        Earth at night – Unsplash
    </a>
    (Accessed: 3 December 2025).
</li> 
        
<li>
    Samoyedness, V. (2021) <em>Exploitation of resources.</em> [Photograph] Available at:
    <a href="https://unsplash.com/photos/a-group-of-people-standing-on-top-of-a-hill-KpKc9SyHII0" target="_blank">
        Exploitation of resources – Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>

<li>
    Shuper, A. (2024) <em>Disinformation image.</em> [Online image] Available at:
    <a href="https://unsplash.com/photos/a-piece-of-paper-with-the-word-phis-on-it-YkEs3Jg51hY" target="_blank">
        Disinformation image – Unsplash
    </a>
    (Accessed: 3 December 2025).
</li>
        
    </div>
</main>

    
